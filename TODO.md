# AutoReject GPU Pipeline - Plan de Diagnostic et Correction

> **Objectif** : Identifier et corriger les divergences entre l'impl√©mentation CPU originale et l'impl√©mentation GPU, en suivant l'ordre chronologique du pipeline.

---

## üìã Vue d'ensemble du Pipeline

```
Donn√©es EEG brutes
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 1: Calcul PTP (Peak-to-Peak)                               ‚îÇ
‚îÇ   CPU: np.ptp(epoch, axis=-1)                                    ‚îÇ
‚îÇ   GPU: torch.max - torch.min                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 2: Augmentation des donn√©es (_clean_by_interp)             ‚îÇ
‚îÇ   CPU: mne.channels.interpolate_bads() + spherical splines       ‚îÇ
‚îÇ   GPU: gpu_interpolation.py (r√©impl√©mentation PyTorch)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 3: Calcul des seuils (_compute_thresh)                     ‚îÇ
‚îÇ   CPU: cross_val_score + GridSearchCV s√©quentiel                 ‚îÇ
‚îÇ   GPU: batched_channel_cv_loss() matriciel                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 4: Vote des √©poques mauvaises                              ‚îÇ
‚îÇ   CPU: _get_bad_epochs() avec np.median                          ‚îÇ
‚îÇ   GPU: _torch_median() + vote tensoriel                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 5: S√©lection des canaux √† interpoler                       ‚îÇ
‚îÇ   CPU: np.argsort + s√©lection s√©quentielle                       ‚îÇ
‚îÇ   GPU: torch.argsort + s√©lection tensorielle                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 6: Interpolation des √©poques (_interpolate_bad_epochs)     ‚îÇ
‚îÇ   CPU: mne.channels.interpolate_bads()                           ‚îÇ
‚îÇ   GPU: interpolate_bads_gpu() + spherical splines PyTorch        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 7: Calcul du score (m√©triques de qualit√©)                  ‚îÇ
‚îÇ   CPU: np.median(np.log(data.var(axis=2)))                       ‚îÇ
‚îÇ   GPU: torch.median + torch.log + torch.var                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 8: Grille de perte et s√©lection finale                     ‚îÇ
‚îÇ   CPU: loss_grid[n_interp, consensus] avec argmin                ‚îÇ
‚îÇ   GPU: loss_grid tensoriel + torch.argmin                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
   R√©sultats finaux (consensus, n_interpolate, thresholds)
```

---

## üî¨ Sprint 1 : √âtape 1 - Calcul PTP (Peak-to-Peak)

### Description
Premi√®re op√©ration sur les donn√©es : calcul de l'amplitude pic-√†-pic pour chaque canal/√©poque.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_compute_thresh()` | ~L250 |
| `autoreject/gpu_pipeline.py` | `batched_channel_cv_loss()` | ~L150 |

### Impl√©mentation CPU originale
```python
# Dans _compute_thresh()
X = epochs.get_data(picks=picks)  # (n_epochs, n_channels, n_times)
ptp = np.ptp(X, axis=-1)  # (n_epochs, n_channels)
```

### Impl√©mentation GPU actuelle
```python
# Dans batched_channel_cv_loss()
data_tensor = torch.tensor(data, dtype=torch.float32, device=device)
ptp = data_tensor.max(dim=-1).values - data_tensor.min(dim=-1).values
```

### T√¢ches
- [x] **1.1** Cr√©er script de diagnostic `benchmarks/diag_step1_ptp.py`
  - Charger un petit dataset (small_fast config)
  - Calculer PTP avec les deux m√©thodes
  - Comparer : `np.allclose(ptp_cpu, ptp_gpu.cpu().numpy(), rtol=1e-5)`
  - Afficher max_diff, mean_diff, positions des divergences
  - ‚úÖ **R√âSULTAT** : PASS - Diff√©rence relative max: 1.1e-7 (acceptable)

- [x] **1.2** V√©rifier l'impact de la pr√©cision float32 vs float64
  - MPS impose float32
  - Calculer la perte de pr√©cision th√©orique
  - Tester avec `torch.float64` sur CPU pour isoler le probl√®me
  - ‚úÖ **R√âSULTAT** : Perte de pr√©cision ~2e-11, n√©gligeable

- [x] **1.3** Documenter les r√©sultats
  - Si divergence > seuil acceptable : corriger
  - Si divergence n√©gligeable : passer √† l'√©tape 2
  - ‚úÖ **R√âSULTAT** : Divergence n√©gligeable ‚Üí PASSER √Ä L'√âTAPE 2

### Crit√®res de validation
- [x] Diff√©rence max PTP < 1e-5 (relatif) ‚úÖ
- [x] Pas de NaN/Inf ‚úÖ
- [x] Formes tensorielles identiques ‚úÖ

---

## üî¨ Sprint 2 : √âtape 2 - Augmentation des donn√©es (_clean_by_interp)

### Description
**√âTAPE CRITIQUE** : Cr√©ation des donn√©es augment√©es par interpolation. C'est ici que la r√©impl√©mentation GPU des splines sph√©riques peut diverger significativement.

### R√©sultat: ‚úÖ VALID√â (apr√®s correction bug critique)

#### üêõ Bug critique corrig√© (1er D√©cembre 2025)

**Probl√®me** : L'interpolation GPU donnait des r√©sultats diff√©rents de MNE (~4500% d'√©cart !).

**Cause racine** : MNE centre les positions des capteurs autour de l'origine de la sph√®re ajust√©e AVANT de calculer la matrice d'interpolation :
```python
# MNE fait (dans _interpolate_bads_eeg):
radius, origin = _fit_sphere(pos_good)
pos_good = pos[goods_idx_pos] - origin  # ‚Üê CENTRAGE !
pos_bad = pos[bads_idx_pos] - origin    # ‚Üê CENTRAGE !
interpolation = _make_interpolation_matrix(pos_good, pos_bad)
```

Notre impl√©mentation ne faisait PAS ce centrage, ce qui changeait significativement la matrice d'interpolation (diff = 0.6, soit 60% des poids !).

**Fichiers corrig√©s** :
1. `autoreject/utils.py` (ligne ~335) : ajout `pos_good -= center`, `pos_bad -= center`
2. `autoreject/gpu_interpolation.py` : 
   - `gpu_interpolate_bads_eeg()` : ajout `_fit_sphere` et centrage
   - `gpu_clean_by_interp()` : ajout `_fit_sphere` et centrage
   - Correction `DeviceArray(data, backend, device)` au lieu de `DeviceArray(data, backend='torch', device=...)`
3. `autoreject/gpu_pipeline.py` :
   - `run_local_reject_cv_gpu()` ligne ~830 : centrage avant normalisation
   - `run_local_reject_cv_gpu_v2()` ligne ~1058 : centrage des positions

#### R√©sultats apr√®s correction

Les tests montrent que l'impl√©mentation GPU est **quasi-identique** √† la version CPU :

| Test | Diff√©rence | R√©sultat |
|------|------------|----------|
| Polyn√¥mes de Legendre | 0 | ‚úÖ IDENTIQUE |
| Fonction G (Green's function) | 0 | ‚úÖ IDENTIQUE |
| Matrice d'interpolation | 2.85e-08 | ‚úÖ PASS |
| `interpolate_bads` vs MNE | 1.44e-11 | ‚úÖ IDENTIQUE |
| `_clean_by_interp` complet | 2.16e-07 (0.27% rel) | ‚úÖ PASS |

La diff√©rence r√©siduelle est due √† float32 (MPS) vs float64 (CPU).

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/utils.py` | `_clean_by_interp()` | ~L180 |
| `autoreject/utils.py` | `interpolate_bads()` | ~L220 |
| `autoreject/gpu_interpolation.py` | `interpolate_bads_gpu()` | ~L50 |
| `autoreject/gpu_interpolation.py` | `_compute_interpolation_matrix_gpu()` | ~L100 |
| `autoreject/gpu_interpolation.py` | `_legendre_table_gpu()` | ~L150 |
| `autoreject/gpu_interpolation.py` | `_calc_g_gpu()` | ~L200 |

### Impl√©mentation CPU originale (MNE)
```python
# Dans interpolate_bads() ‚Üí appelle MNE
epochs_interp = epochs.copy()
epochs_interp.info['bads'] = bad_chs
epochs_interp.interpolate_bads(reset_bads=True)
# Utilise : mne.channels.interpolation._make_interpolation_matrix()
# Bas√© sur : Green's function pour splines sph√©riques
# Pr√©cision : float64
```

### Impl√©mentation GPU actuelle
```python
# Dans interpolate_bads_gpu()
interp_matrix = _compute_interpolation_matrix_gpu(pos_good, pos_bad, device)
# Utilise : Legendre polynomials table + calcul G matriciel
# Pr√©cision : float32 (contrainte MPS)
```

### T√¢ches
- [x] **2.1** Cr√©er script de diagnostic `benchmarks/diag_step2_interp.py`
  - Prendre 1 √©poque avec 1 canal marqu√© mauvais
  - Interpoler avec CPU (MNE) et GPU
  - Comparer les donn√©es interpol√©es canal par canal
  - ‚úÖ **R√âSULTAT** : PASS - Good channels identiques, bad channel diff < 1e-5

- [x] **2.2** Isoler la matrice d'interpolation
  - Extraire `interp_matrix` des deux impl√©mentations
  - Comparer √©l√©ment par √©l√©ment
  - Identifier les sources de divergence (Legendre? G? inversion?)
  - ‚úÖ **R√âSULTAT** : PASS - Diff max = 1.8e-8

- [x] **2.3** V√©rifier le calcul des polyn√¥mes de Legendre
  ```python
  # CPU: scipy.special.lpmv ou table pr√©calcul√©e MNE
  # GPU: _legendre_table_gpu() ‚Üí r√©currence manuelle
  ```
  - Comparer les tables de Legendre pour n=1..7, m=0..n
  - ‚úÖ **R√âSULTAT** : PASS - Diff = 0 (identique)

- [x] **2.4** V√©rifier le calcul de la fonction G (Green's function)
  ```python
  # G(x) = 1/(4œÄ) * Œ£ (2l+1)/(l(l+1)) * P_l(cos(Œ∏))
  ```
  - Comparer les matrices G
  - ‚úÖ **R√âSULTAT** : PASS - Diff = 0 (identique)

- [x] **2.5** V√©rifier l'inversion de matrice
  ```python
  # CPU: np.linalg.lstsq ou solve
  # GPU: torch.linalg.lstsq
  ```
  - Comparer les solutions
  - ‚úÖ **R√âSULTAT** : PASS - Int√©gr√© dans test matrice

- [x] **2.6** Quantifier l'erreur d'interpolation
  - MSE entre donn√©es interpol√©es CPU vs GPU
  - Visualiser les diff√©rences spatiales
  - ‚úÖ **R√âSULTAT** : PASS - Max rel diff = 2.8e-5 (0.003%)

### Crit√®res de validation
- [x] Matrice d'interpolation : diff max < 1e-4 ‚úÖ (diff = 1.8e-8)
- [x] Donn√©es interpol√©es : MSE < 1e-6 ‚úÖ (diff = 1e-12)
- [x] Pas de NaN/Inf dans les r√©sultats ‚úÖ

---

## üî¨ Sprint 3 : √âtape 3 - Calcul des seuils (_compute_thresh)

### Description
Cross-validation pour trouver le seuil optimal de rejet par canal. L'impl√©mentation GPU utilise une approche matricielle batch au lieu de boucles s√©quentielles.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_compute_thresh()` | ~L230-350 |
| `autoreject/autoreject.py` | `_ChannelAutoReject` | ~L150-200 |
| `autoreject/gpu_pipeline.py` | `GPUThresholdOptimizer` | ~L50-300 |
| `autoreject/gpu_pipeline.py` | `batched_channel_cv_loss()` | ~L150-250 |

### Impl√©mentation CPU originale
```python
# Dans _compute_thresh()
for ch_idx in range(n_channels):
    X = epochs.get_data(picks=[ch_idx])
    cv = StratifiedKFold(n_splits=cv, shuffle=False)
    param_grid = {'thresh': threshes}
    gs = GridSearchCV(_ChannelAutoReject(), param_grid, cv=cv, scoring='neg_mean_squared_error')
    gs.fit(X, y)  # y = labels des √©poques (good/bad bas√© sur PTP)
    best_thresh[ch_idx] = gs.best_params_['thresh']
```

### Impl√©mentation GPU actuelle
```python
# Dans batched_channel_cv_loss()
# 1. Calcul PTP pour tous les canaux en batch
ptp = data.max(dim=-1).values - data.min(dim=-1).values  # (n_epochs, n_channels)

# 2. Pour chaque seuil, calcul du loss en batch
for thresh in threshes:
    bad_mask = ptp > thresh  # (n_epochs, n_channels)
    # Calcul loss via CV folds matriciel
    losses[thresh_idx] = compute_cv_loss_batch(...)

# 3. S√©lection du meilleur seuil par canal
best_thresh = threshes[losses.argmin(dim=0)]
```

### T√¢ches
- [ ] **3.1** Cr√©er script de diagnostic `benchmarks/diag_step3_thresh.py`
  - Ex√©cuter les deux impl√©mentations sur 1 canal
  - Comparer les seuils trouv√©s
  - Comparer les courbes de loss

- [ ] **3.2** V√©rifier la logique de cross-validation
  - Les folds sont-ils identiques ?
  - L'ordre des √©poques est-il pr√©serv√© ?

- [ ] **3.3** V√©rifier le calcul du loss
  ```python
  # CPU: neg_mean_squared_error sur donn√©es reconstruites
  # GPU: MSE tensoriel
  ```
  - Comparer les scores par fold

- [ ] **3.4** V√©rifier le scoring
  - CPU utilise `scoring='neg_mean_squared_error'`
  - GPU utilise-t-il la m√™me m√©trique ?

- [ ] **3.5** V√©rifier la gestion des cas limites
  - Que se passe-t-il si tous les epochs sont bons/mauvais ?
  - Comportement avec seuil = min(ptp) ou max(ptp) ?

### Crit√®res de validation
- [ ] Seuils identiques √† ¬±5% (tol√©rance pour variations CV)
- [ ] Courbes de loss similaires (corr√©lation > 0.95)
- [ ] Meilleur seuil dans le m√™me "voisinage"

---

## üî¨ Sprint 4 : √âtape 4 - Vote des √©poques mauvaises

### Description
D√©termination des √©poques √† rejeter bas√©e sur le consensus entre canaux.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_get_bad_epochs()` | ~L400 |
| `autoreject/gpu_pipeline.py` | `_get_bad_epochs_gpu()` | ~L350 |

### Impl√©mentation CPU originale
```python
def _get_bad_epochs(self, epochs, picks, threshes):
    X = epochs.get_data(picks=picks)
    ptp = np.ptp(X, axis=-1)  # (n_epochs, n_channels)
    bad_epoch_counts = np.zeros(len(epochs))
    for ch_idx, thresh in enumerate(threshes):
        bad_epoch_counts += (ptp[:, ch_idx] > thresh)
    n_bad_channels = bad_epoch_counts
    bad_epochs = n_bad_channels > (len(picks) * consensus)
    return bad_epochs
```

### Impl√©mentation GPU actuelle
```python
def _get_bad_epochs_gpu(data, threshes, consensus, device):
    ptp = data.max(dim=-1).values - data.min(dim=-1).values
    bad_mask = ptp > threshes.unsqueeze(0)  # broadcast
    n_bad_channels = bad_mask.sum(dim=1)
    bad_epochs = n_bad_channels > (n_channels * consensus)
    return bad_epochs
```

### T√¢ches
- [ ] **4.1** Cr√©er script de diagnostic `benchmarks/diag_step4_vote.py`
  - Comparer `bad_epochs` CPU vs GPU
  - Comparer `n_bad_channels` par √©poque

- [ ] **4.2** V√©rifier le broadcasting des seuils
  - CPU: boucle sur canaux
  - GPU: broadcast (n_epochs, 1) vs (n_channels,)
  - V√©rifier que les dimensions sont correctes

- [ ] **4.3** V√©rifier le calcul du consensus
  - `consensus * n_channels` arrondi pareil ?
  - Comparaison `>` vs `>=` ?

### Crit√®res de validation
- [ ] `bad_epochs` identiques (100% match)
- [ ] `n_bad_channels` identiques

---

## üî¨ Sprint 5 : √âtape 5 - S√©lection des canaux √† interpoler

### Description
Pour chaque √©poque, s√©lection des K canaux les plus "mauvais" √† interpoler.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_run_local_reject_cv()` | ~L850 |
| `autoreject/gpu_pipeline.py` | `run_local_reject_cv_gpu()` | ~L600 |

### Impl√©mentation CPU originale
```python
# Dans _run_local_reject_cv()
for epoch_idx in range(n_epochs):
    bad_chs_idx = np.argsort(ptp[epoch_idx])[-n_interpolate:]
    bad_chs = [ch_names[i] for i in bad_chs_idx]
    # Interpoler ces canaux
```

### Impl√©mentation GPU actuelle
```python
# Dans run_local_reject_cv_gpu()
sorted_indices = torch.argsort(ptp, dim=1, descending=True)
bad_chs_indices = sorted_indices[:, :n_interpolate]
```

### T√¢ches
- [ ] **5.1** Cr√©er script de diagnostic `benchmarks/diag_step5_select.py`
  - Comparer les canaux s√©lectionn√©s pour interpolation
  - V√©rifier l'ordre de tri

- [ ] **5.2** V√©rifier le comportement avec √©galit√©s
  - Si deux canaux ont le m√™me PTP, l'ordre est-il d√©terministe ?
  - `np.argsort` vs `torch.argsort` : stable sort ?

- [ ] **5.3** V√©rifier les indices vs noms de canaux
  - Mapping correct entre indices et noms ?

### Crit√®res de validation
- [ ] Canaux s√©lectionn√©s identiques (ou √©quivalents si √©galit√© PTP)
- [ ] Ordre de s√©lection coh√©rent

---

## üî¨ Sprint 6 : √âtape 6 - Interpolation des √©poques

### Description
**√âTAPE CRITIQUE #2** : Interpolation effective des canaux s√©lectionn√©s. R√©utilise les fonctions de l'√©tape 2 mais appliqu√©es dans le contexte de la CV.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_interpolate_bad_epochs()` | ~L750 |
| `autoreject/gpu_pipeline.py` | `_interpolate_epochs_gpu()` | ~L500 |

### Impl√©mentation CPU originale
```python
def _interpolate_bad_epochs(self, epochs, bad_epochs_idx, bad_chs_per_epoch):
    epochs_interp = epochs.copy()
    for epoch_idx in bad_epochs_idx:
        bad_chs = bad_chs_per_epoch[epoch_idx]
        # Cr√©er une "mini-epoch" avec ce seul epoch
        epoch_data = epochs_interp[epoch_idx]
        epoch_data.info['bads'] = bad_chs
        epoch_data.interpolate_bads()
        epochs_interp._data[epoch_idx] = epoch_data.get_data()
    return epochs_interp
```

### Impl√©mentation GPU actuelle
```python
def _interpolate_epochs_gpu(data, bad_chs_indices, interp_matrix, device):
    # Batch interpolation
    for epoch_idx in range(n_epochs):
        bad_idx = bad_chs_indices[epoch_idx]
        good_idx = ~bad_idx
        data[epoch_idx, bad_idx] = interp_matrix @ data[epoch_idx, good_idx]
    return data
```

### T√¢ches
- [ ] **6.1** Cr√©er script de diagnostic `benchmarks/diag_step6_interp_epochs.py`
  - Appliquer les deux m√©thodes sur les m√™mes √©poques/canaux
  - Comparer les donn√©es r√©sultantes

- [ ] **6.2** V√©rifier la matrice d'interpolation dynamique
  - La matrice change-t-elle selon les canaux mauvais ?
  - Est-elle recalcul√©e correctement √† chaque fois ?

- [ ] **6.3** V√©rifier le batch processing
  - L'interpolation batch GPU est-elle √©quivalente aux appels s√©quentiels CPU ?

### Crit√®res de validation
- [ ] Donn√©es interpol√©es : MSE < 1e-5
- [ ] Pas de "fuites" d'information entre √©poques

---

## üî¨ Sprint 7 : √âtape 7 - Calcul du score

### Description
Calcul de la m√©trique de qualit√© pour √©valuer chaque configuration (n_interpolate, consensus).

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `BaseAutoReject.score()` | ~L120 |
| `autoreject/gpu_pipeline.py` | `_compute_score_gpu()` | ~L450 |

### Impl√©mentation CPU originale
```python
def score(self, epochs):
    """Return the negative median log variance."""
    X = epochs.get_data()
    var = np.var(X, axis=2)  # variance par canal/√©poque
    log_var = np.log(var)
    return -np.median(log_var)
```

### Impl√©mentation GPU actuelle
```python
def _compute_score_gpu(data, device):
    var = data.var(dim=-1)
    log_var = torch.log(var)
    return -_torch_median(log_var)
```

### T√¢ches
- [ ] **7.1** Cr√©er script de diagnostic `benchmarks/diag_step7_score.py`
  - Calculer le score avec les deux m√©thodes
  - Comparer les valeurs

- [ ] **7.2** V√©rifier `_torch_median()` vs `np.median()`
  ```python
  # np.median avec n pair : moyenne des deux valeurs centrales
  # torch.median : valeur centrale inf√©rieure
  ```
  - Cette diff√©rence peut causer des divergences !

- [ ] **7.3** V√©rifier le log de petites variances
  - `log(0)` = -inf : g√©r√© pareil ?
  - Variances tr√®s petites ‚Üí instabilit√© num√©rique ?

### Crit√®res de validation
- [ ] Scores identiques √† ¬±1e-3
- [ ] Pas de NaN/Inf

---

## üî¨ Sprint 8 : √âtape 8 - Grille de perte et s√©lection finale

### Description
Construction de la grille de perte pour toutes les combinaisons (n_interpolate, consensus) et s√©lection de la meilleure.

### Fichiers concern√©s
| Fichier | Fonction | Ligne(s) |
|---------|----------|----------|
| `autoreject/autoreject.py` | `_run_local_reject_cv()` | ~L900 |
| `autoreject/gpu_pipeline.py` | `run_local_reject_cv_gpu()` | ~L700 |

### Impl√©mentation CPU originale
```python
# Dans _run_local_reject_cv()
loss_grid = np.zeros((len(n_interpolates), len(consensuses)))
for i, n_interp in enumerate(n_interpolates):
    for j, cons in enumerate(consensuses):
        # Appliquer n_interp et cons
        epochs_clean = self._apply_interp_and_reject(epochs, n_interp, cons)
        loss_grid[i, j] = -self.score(epochs_clean)

# Trouver le minimum
best_idx = np.unravel_index(loss_grid.argmin(), loss_grid.shape)
best_n_interp = n_interpolates[best_idx[0]]
best_consensus = consensuses[best_idx[1]]
```

### Impl√©mentation GPU actuelle
```python
# Dans run_local_reject_cv_gpu()
loss_grid = torch.zeros((len(n_interpolates), len(consensuses)), device=device)
# ... calcul parall√©lis√© ...
best_idx = loss_grid.argmin()
best_i, best_j = best_idx // len(consensuses), best_idx % len(consensuses)
```

### T√¢ches
- [ ] **8.1** Cr√©er script de diagnostic `benchmarks/diag_step8_grid.py`
  - Comparer les grilles de perte compl√®tes
  - Visualiser les diff√©rences

- [ ] **8.2** V√©rifier le calcul de l'argmin
  - `np.unravel_index` vs division/modulo PyTorch
  - Comportement si plusieurs minima √©gaux ?

- [ ] **8.3** V√©rifier l'accumulation des erreurs
  - Les erreurs des √©tapes pr√©c√©dentes s'accumulent-elles ?
  - Quelle est la contribution de chaque √©tape √† l'erreur finale ?

### Crit√®res de validation
- [ ] Grilles de perte : corr√©lation > 0.99
- [ ] M√™me minimum s√©lectionn√© (ou √©quivalent)

---

## üìä Scripts de diagnostic √† cr√©er

```
benchmarks/
‚îú‚îÄ‚îÄ diag_step1_ptp.py
‚îú‚îÄ‚îÄ diag_step2_interp.py
‚îú‚îÄ‚îÄ diag_step3_thresh.py
‚îú‚îÄ‚îÄ diag_step4_vote.py
‚îú‚îÄ‚îÄ diag_step5_select.py
‚îú‚îÄ‚îÄ diag_step6_interp_epochs.py
‚îú‚îÄ‚îÄ diag_step7_score.py
‚îú‚îÄ‚îÄ diag_step8_grid.py
‚îî‚îÄ‚îÄ diag_full_comparison.py  # Ex√©cute tout et g√©n√®re un rapport
```

---

## üéØ M√©triques de succ√®s globales

| M√©trique | Objectif | Priorit√© |
|----------|----------|----------|
| Consensus match | 100% | P0 |
| n_interpolate match | ¬±1 | P0 |
| Thresholds correlation | >0.99 | P1 |
| Temps GPU < CPU | ‚â•2x speedup | P2 |
| M√©moire GPU | <4GB pour 128ch | P2 |

---

## üìù Notes

### Sur le dossier legacy/
> **Question** : Est-ce utile de mettre le code original dans un dossier `legacy/` ?

**Oui, tr√®s utile pour** :
- Avoir une r√©f√©rence "ground truth" facilement accessible
- Pouvoir importer et comparer directement dans les scripts de diagnostic
- √âviter de chercher dans l'historique git

**Structure sugg√©r√©e** :
```
legacy/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ autoreject_original.py   # Copie de autoreject.py avant modifications
‚îú‚îÄ‚îÄ utils_original.py        # Copie de utils.py avant modifications
‚îî‚îÄ‚îÄ README.md                # Explication de la version
```

---

## üöÄ Prochaine action

**Sprint 1 - T√¢che 1.1** : Cr√©er `benchmarks/diag_step1_ptp.py` et valider que le calcul PTP est identique.
